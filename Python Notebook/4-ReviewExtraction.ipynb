{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time # for sleep time\n",
    "import re\n",
    "import functools\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome(executable_path=r'C:\\Users\\Xitong Hu\\Desktop\\Class\\BAN5193\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the URL list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Chicago_hotel_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.hotels.com/travelads/trackredirect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.hotels.com/travelads/trackredirect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.hotels.com/ho148843/?q-check-out=2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.hotels.com/ho422531/?pa=5&amp;tab=desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>https://www.hotels.com/ho1480392704/?pa=464&amp;ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>https://www.hotels.com/ho537680/?pa=465&amp;tab=de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>https://www.hotels.com/ho474678/?pa=466&amp;tab=de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>https://www.hotels.com/ho311002/?pa=467&amp;tab=de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>https://www.hotels.com/ho1667246112/?pa=468&amp;ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url\n",
       "0    https://www.hotels.com/ho106418/?q-check-out=2...\n",
       "1    https://www.hotels.com/travelads/trackredirect...\n",
       "2    https://www.hotels.com/travelads/trackredirect...\n",
       "3    https://www.hotels.com/ho148843/?q-check-out=2...\n",
       "4    https://www.hotels.com/ho422531/?pa=5&tab=desc...\n",
       "..                                                 ...\n",
       "461  https://www.hotels.com/ho1480392704/?pa=464&ta...\n",
       "462  https://www.hotels.com/ho537680/?pa=465&tab=de...\n",
       "463  https://www.hotels.com/ho474678/?pa=466&tab=de...\n",
       "464  https://www.hotels.com/ho311002/?pa=467&tab=de...\n",
       "465  https://www.hotels.com/ho1667246112/?pa=468&ta...\n",
       "\n",
       "[466 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to scrap review from a sample url, hotel_all_links[0]. This section shows the some process of how to extract review features from one URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hotel_all_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get(hotel_all_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After open the hotel page, we need to click the see all review button to read more reviews.\n",
    "#See_all_reviews_button = driver.find_elements_by_xpath('//div[@class=\"see-all-reviews\"]/a[@class=\"cta\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See_all_reviews_button[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the review features in the first review page\n",
    "#Review=driver.find_elements_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[*]/blockquote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write loop to exctract reviews from 100 hotel urls. For each hotel, we are going to extract at max 100 most recent reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     https://www.hotels.com/ho106418/?q-check-out=2...\n",
       "1     https://www.hotels.com/travelads/trackredirect...\n",
       "2     https://www.hotels.com/travelads/trackredirect...\n",
       "3     https://www.hotels.com/ho148843/?q-check-out=2...\n",
       "4     https://www.hotels.com/ho422531/?pa=5&tab=desc...\n",
       "5     https://www.hotels.com/ho218070/?q-check-out=2...\n",
       "6     https://www.hotels.com/travelads/trackredirect...\n",
       "7     https://www.hotels.com/travelads/trackredirect...\n",
       "8     https://www.hotels.com/ho482991/?q-check-out=2...\n",
       "9     https://www.hotels.com/ho122910/?q-check-out=2...\n",
       "10    https://www.hotels.com/ho421352/?pa=11&tab=des...\n",
       "11    https://www.hotels.com/ho1462835840/?q-check-o...\n",
       "12    https://www.hotels.com/ho862142112/?q-check-ou...\n",
       "13    https://www.hotels.com/ho265809/?q-check-out=2...\n",
       "14    https://www.hotels.com/ho310742/?q-check-out=2...\n",
       "15    https://www.hotels.com/ho699797/?q-check-out=2...\n",
       "16    https://www.hotels.com/ho126022/?q-check-out=2...\n",
       "17    https://www.hotels.com/travelads/trackredirect...\n",
       "18    https://www.hotels.com/ho179221/?q-check-out=2...\n",
       "19    https://www.hotels.com/ho112743/?q-check-out=2...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset the whole url list to small lists.\n",
    "hotel_all_links=df[\"url\"]\n",
    "hotel_1=hotel_all_links[0:20]\n",
    "hotel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So in this scraping process, it only shows the process for the first 20 url links.\n",
    "#We need to muanlly change the slice number to create another subset until we scrape 100 url links.\n",
    "#such as:\n",
    "#url20_50=list(hotel_all_links[20:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list to scrap reviews\n",
    "Rate_list=[]\n",
    "Review_id=[]\n",
    "Date=[]\n",
    "Reviews=[]\n",
    "URL_ID=[]\n",
    "Hotel_Name=[]\n",
    "error=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hotels.com/ho106418/?q-check-out=2020-10-27&FPQ=2&q-check-in=2020-10-26&WOE=2&WOD=1&q-room-0-children=0&pa=1&tab=description&JHR=1&q-room-0-adults=2&YGF=2&MGT=1&ZSX=0&SYE=3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "https://www.hotels.com/travelads/trackredirect.html?trackingUrl=H4sIAAAAAAAAAC2U266qOhiF38arhbPlVFiJ2QERURA5iegNAVrlDAoC8vSbPbN70ZFv5B9NRtM07fu2-_vzM47jmjwjPJB3n3VZ_VwnTfXTv6OBlBLufgb44_0P2zJLin960vU-eXdZU5-X0DvDZMOKPFyDPyJglx1xv4BoyK3hH4GGwkICgnBN_xFEWlgzyyD4NRkWLeZC_-UEkaOXABJF-ndyiS9HIlpcTBFB_j8SAPMrNPsr_CKrd1QXG7hKohpnOOqJVu0_Gd6wEc0TwBEqEgBNsRESqYjlGCpiBC7BTMxFDLNaeibFUlqJ-mgjLWun7TXv3MuJ2TFH5OeHaxvehYmnfB2S206laZkdBR09lJiDSRYlVSfrWUmlkWcleIq3KT-_M0ejM4-fchzH24Eb7cNx1jJtW6XKHKSTQvaZpdTp2H2r4dkJbmub4iN60PNY21lFj9fHdgzOvU8dvJP6eWiVDrR7NBr7tOJNyYJNdxRBFPLTRUypl9UXWDdiz_FB9pGYkTeRN50vnK9O5_seCKhCV_x2SARK8envyym24jrd5awT86G0g-MsEJvuinLaAutIJke-OrXWlgGMCtmPj8zQd3ksFKHUPo8X7jYQrPBsY8h9bdCs8hUYv1WMQcuV282-fCvcgu-2sxu9xVIM31J1uxqU67uhqMtFZzX0vcC3XorsnBjWQXWLLvcyKSJySBTJxcC1dnILerJ05D61TJ97p5XVF-Z8dys_hajw2KRguEBRBGtStA59nzPLikUbnrMJNeJQplgBnK3uDViwO2k4Es8zKvXuWduv2OPzt2jaXfgFcZA5496xLhXscpwLVlMqteE3nHmqWfMr20z5cC6RWgeqokHv0AuyHqs1eunvFJyCz40PAlYfvVdguYJvnagvKM5fgKZpL2BcVEO0n4-nOkSoPJkEH_tthctwKLYydRVnxQltfxgt-BpVUQIOTztn46WmPK4qYzhiYBKidy9XFnaKIqtd7SefOD9KHcrN3kuutYO20lwGqJ0Y82gR_zZfl7d_2Q5vYEF7N_tzcGVfFiJHPs8_o--JfUSFhN_dK2kCpno144KN-oAYNhM-JDcc8YQ73gutWeAe1Ti6bOs76SVl668uQs-nGuultvNO_fDLrYiJdnzfd_71pKXbyx4Grl0eGncge_ahF9_8GqV42vV4yIOTv59MNomDtwkp-NCFAYXp1SxYuQzuvuGehEPzehbGDQOLPLMoau6Mf_OlWEefWnzdaYO-MjsNCBkIt_M8m--Ya5DZt48G8n5Tz04ZxiqkkDvm0-X9ZlE2B719en2oliO-HFxrFbTSJf4qwuDUQ9bkd_qRQltKvnEHkWLqZySEjmrnk73ZrLqy6buN5jqhtGqbLuuXv25Dr2ISJU196LoPwRsa0ICCgKJZD_J_IfoLwOrTkffB2kBGXCNhTdNozdH_An22iSBoBQAA&targetUrl=H4sIAAAAAAAAANPPyDcxMjK0MNG3L9RNzkhNztbNLy2xNTIwMtA1NNA1MldzCwi0NVaDSWbmIeTM1ML9XW2NgKSLrSFQRVF-fq6uAVBhZk5KUWqerYFaQSJQuiQxyTYltTi5KLOgJDM_T83LIwgoCleemFKaU1IMFIl0dwOSvu4hQMOigiOA2oMjXW2NAdDJWbmiAAAA\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7cd9aea14576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mRate_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[*]/div[1]/span[1]/span[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRate_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;31m#Get the rating of one review, if error occures, assign \"NA\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for url in hotel_1: #change the hotel_1 to other subset names when process the next group.\n",
    "    #get open the url in the selenium browser.\n",
    "    driver.get(url)\n",
    "    #pring the current url for checing the loop process\n",
    "    print(url)\n",
    "    #We need to add some sleep seconds after open the url page.\n",
    "    time.sleep(15)\n",
    "    #Srape the title of the hotel in the main page\n",
    "    title=driver.find_element_by_xpath('//div[@class=\"vcard\"]/h1').text\n",
    "    #Find the see all reviews button at the main page and click it. Sometimes, a hotel might not have reveiw information.\n",
    "    #In such condition, an error will occure. \n",
    "    #So we use try except continue to supress the error and continue to next url,if a page does not have see all review button.\n",
    "    try:\n",
    "        See_all_reviews_button = driver.find_elements_by_xpath('//div[@class=\"see-all-reviews\"]/a[@class=\"cta\"]')\n",
    "        See_all_reviews_button[0].click()\n",
    "    except:\n",
    "        print(url+\"error\")\n",
    "        continue\n",
    "\n",
    "    c = 0\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Get the total review number for the hotel\n",
    "    Total_Review=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[1]/ul/li[1]/a/span').text\n",
    "    Total_Review_num=int(re.sub(r\"[()]\", \"\", Total_Review))\n",
    "    \n",
    "    #since we only scrape the first 100 reviews for a hotel, so we need to loop 2 times to get 100 reviews (50 reviews per page)\n",
    "    while c < 2:\n",
    "        #for some reviews, partial conents were shown, we need to click the expanable button to show the whole comments.\n",
    "        #click the expanable_buttons to show the whole comments\n",
    "        Expanable_buttons=driver.find_elements_by_xpath('//div[@class=\"expandable-wrapper\"]/span/button')\n",
    "        try: # not all pages have buttons\n",
    "            for a in range(0, len(Expanable_buttons)):\n",
    "                Expanable_buttons[a].click()\n",
    "                time.sleep(20)\n",
    "        except:\n",
    "               error=\"no_read_more\"\n",
    "        #start to write a inside loop to extract review features one by one. \n",
    "        #Because a review does not alway include all features, so we need to etract them one by one for their features.\n",
    "        \n",
    "        #start the inside loop, the maximum review amounts in a page is equal to the rating occurence in the review list.\n",
    "        #we can set it to maximum 50 per review page, but it will raise error if a page includes less than 50 reviews. \n",
    "        Rate_len=driver.find_elements_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[*]/div[1]/span[1]/span[1]')\n",
    "        for x in range(1,len(Rate_len)+1):\n",
    "            time.sleep(2)\n",
    "            #Get the rating of one review, if error occures, assign \"NA\".\n",
    "            try:\n",
    "                Rate=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[%d]/div[1]/span[1]/span[1]' %x) \n",
    "                Rate_list.append(Rate.text)\n",
    "            except:\n",
    "                Rate_list.append(\"NA\")\n",
    "            #Get the date of one review, if error occures, assign \"NA\".\n",
    "            try:\n",
    "                Date_1=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[%d]/div[1]/span[2]' %x)\n",
    "                Date.append(Date_1.text)\n",
    "            except:\n",
    "                Date.append(\"NA\")\n",
    "            #Write the url inforamtion for this review\n",
    "            URL_ID.append(url)\n",
    "            #Write the hotel name for this reveiw\n",
    "            Hotel_Name.append(title)\n",
    "            #check the progress when loop is runing. It shows which comment we are currently scraping.\n",
    "            print(c*50+x)\n",
    "            #Scrape the review\n",
    "            try:\n",
    "                Review=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[%d]/blockquote' %x)\n",
    "                Reviews.append(Review.text)\n",
    "            except:\n",
    "                #sometimes, even the xpath is correct, it also raises an error. So I make it sleep 10 seconds and try it again.\n",
    "                try:\n",
    "                    time.sleep(10)\n",
    "                    Review=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[%d]/blockquote' %x)\n",
    "                    Reviews.append(Review.text)\n",
    "                except:\n",
    "                    #there's another xpath for the review content\n",
    "                    try:\n",
    "                        Review=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[%d]/div[2]/blockquote' %x)\n",
    "                        Reviews.append(Review.text)\n",
    "                    except:\n",
    "                        #if above conditions are not met, assign \"Error\" for this review.\n",
    "                        Review=\"Error\"\n",
    "                        Reviews.append(Review)\n",
    "                        pass\n",
    "                \n",
    "        #After scraping the first 50 reviews, we need to click next button to the next review page.\n",
    "        #There are two possible xpaths for next_button.\n",
    "        #time.sleep(10)\n",
    "        try:\n",
    "            next_button=driver.find_element_by_xpath('//div[@class=\"pagination-controls\"]/a[2]')\n",
    "            next_button.click()\n",
    "        except:\n",
    "            try:\n",
    "                next_button_first_page=driver.find_element_by_xpath('//*[@id=\"guest-reviews\"]/div[2]/div[1]/div[3]/div[2]/div[51]/div[2]/a')\n",
    "                next_button_first_page.click()\n",
    "            except:\n",
    "                pass\n",
    "        #Add conditions to avoid some errors, for example, if a review page does not have read more option in the first page,\n",
    "        #an error will occure and it will make the loop to the next page to scrape features. \n",
    "        #So we add conditions to make it in the loop even there's no read more option for reviews.\n",
    "        if error == \"no_read_more\" and Total_Review_num >50 and Rate == \"\":\n",
    "            c=c\n",
    "        elif Total_Review_num <50:\n",
    "            c=c+2\n",
    "        else:\n",
    "            c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataframe based on the attributes we collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(URL_ID,Hotel_Name,Date, Rate_list, Reviews)), \n",
    "               columns =['URL','Hotel_Name','Date', 'Rate','Review']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to the csv file\n",
    "df.to_csv(\"List1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section shows all the subset csv files of the first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"List1.csv\")\n",
    "df2=pd.read_csv(\"List2_10.csv\")\n",
    "df3=pd.read_csv(\"List11_30.csv\")\n",
    "df4=pd.read_csv(\"List31_45.csv\")\n",
    "df5=pd.read_csv(\"List46_59.csv\")\n",
    "df6=pd.read_csv(\"List60_63.csv\")\n",
    "df7=pd.read_csv(\"List64_99.csv\")\n",
    "df8=pd.read_csv(\"List100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append into one dataframe and delete the duplicates. My loop function scrapes the reviews twice under certain error condition.\n",
    "#due to the limit of the time, haven't fix this bug. But it does not effect the data quality.\n",
    "df_final=df1.append(df2).append(df3).append(df4).append(df5).append(df6).append(df7).append(df8).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "      <td>The Whitehall Hotel</td>\n",
       "      <td>Check-in Oct 19, 2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>It was a good stay there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "      <td>The Whitehall Hotel</td>\n",
       "      <td>Check-in Oct 20, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very disappointing. Hallway carpets very old a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "      <td>The Whitehall Hotel</td>\n",
       "      <td>Check-in Oct 18, 2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cheap room, not clean. Water damage EVERYWHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "      <td>The Whitehall Hotel</td>\n",
       "      <td>Check-in Oct 17, 2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>The staff was extremely accommodating and nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.hotels.com/ho106418/?q-check-out=2...</td>\n",
       "      <td>The Whitehall Hotel</td>\n",
       "      <td>Check-in Oct 17, 2020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The comforter was disgusting. We didn’t realiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>https://www.hotels.com/ho1168217056/?q-check-o...</td>\n",
       "      <td>Nobu Hotel Chicago</td>\n",
       "      <td>Check-in Aug 12, 2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>https://www.hotels.com/ho1168217056/?q-check-o...</td>\n",
       "      <td>Nobu Hotel Chicago</td>\n",
       "      <td>Check-in Jul 9, 2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>https://www.hotels.com/ho1168217056/?q-check-o...</td>\n",
       "      <td>Nobu Hotel Chicago</td>\n",
       "      <td>Check-in Jul 3, 2020</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>https://www.hotels.com/ho1168217056/?q-check-o...</td>\n",
       "      <td>Nobu Hotel Chicago</td>\n",
       "      <td>Check-in Jul 3, 2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>https://www.hotels.com/ho1168217056/?q-check-o...</td>\n",
       "      <td>Nobu Hotel Chicago</td>\n",
       "      <td>Check-in Jul 4, 2020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9621 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL           Hotel_Name  \\\n",
       "0   https://www.hotels.com/ho106418/?q-check-out=2...  The Whitehall Hotel   \n",
       "1   https://www.hotels.com/ho106418/?q-check-out=2...  The Whitehall Hotel   \n",
       "2   https://www.hotels.com/ho106418/?q-check-out=2...  The Whitehall Hotel   \n",
       "3   https://www.hotels.com/ho106418/?q-check-out=2...  The Whitehall Hotel   \n",
       "4   https://www.hotels.com/ho106418/?q-check-out=2...  The Whitehall Hotel   \n",
       "..                                                ...                  ...   \n",
       "28  https://www.hotels.com/ho1168217056/?q-check-o...   Nobu Hotel Chicago   \n",
       "29  https://www.hotels.com/ho1168217056/?q-check-o...   Nobu Hotel Chicago   \n",
       "30  https://www.hotels.com/ho1168217056/?q-check-o...   Nobu Hotel Chicago   \n",
       "31  https://www.hotels.com/ho1168217056/?q-check-o...   Nobu Hotel Chicago   \n",
       "32  https://www.hotels.com/ho1168217056/?q-check-o...   Nobu Hotel Chicago   \n",
       "\n",
       "                     Date  Rate  \\\n",
       "0   Check-in Oct 19, 2020   8.0   \n",
       "1   Check-in Oct 20, 2020   4.0   \n",
       "2   Check-in Oct 18, 2020   4.0   \n",
       "3   Check-in Oct 17, 2020  10.0   \n",
       "4   Check-in Oct 17, 2020   6.0   \n",
       "..                    ...   ...   \n",
       "28  Check-in Aug 12, 2020  10.0   \n",
       "29   Check-in Jul 9, 2020   8.0   \n",
       "30   Check-in Jul 3, 2020  10.0   \n",
       "31   Check-in Jul 3, 2020   8.0   \n",
       "32   Check-in Jul 4, 2020   6.0   \n",
       "\n",
       "                                               Review  \n",
       "0                            It was a good stay there  \n",
       "1   Very disappointing. Hallway carpets very old a...  \n",
       "2   Cheap room, not clean. Water damage EVERYWHERE...  \n",
       "3   The staff was extremely accommodating and nice...  \n",
       "4   The comforter was disgusting. We didn’t realiz...  \n",
       "..                                                ...  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "\n",
       "[9621 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of distinct URL\n",
    "len(df_final.URL.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"Reviews_100_URL.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
